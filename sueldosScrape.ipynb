{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Web Scraping Gobierno Transparente Chile\n",
    "##### Exploring wage expenses in the goberment. Public information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Beautiful soup did not work. The server time outs when you connect through bsoup.\n",
    "\n",
    "## Trying Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import unicodedata\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import sys\n",
    "sys.path.append('./lib/')\n",
    "#from functions import *\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from unidecode import unidecode\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def createCustomDataFrame():\n",
    "   \n",
    "    columns = ['entity', 'department', 'type_contract', 'year', 'month', 'Estamento', 'Apellido paterno', 'Apellido materno', 'Nombres', 'Grado EUS',\t'Calificación profesional o formación', 'Cargo', 'Región',\t'Asignaciones especiales', 'Unidad monetaria', 'Remuneración Bruta Mensualizada', 'Horas extraordinarias', 'Fecha de inicio', 'Fecha de término', 'Observaciones']\n",
    "    \n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    #df = cleanData(df)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "def cleanData(df):\n",
    "\n",
    "# Another way to do the same\n",
    "#    pd.concat([df[col].astype(str).str.upper() for col in df.columns], axis=1)\n",
    "    df = df.str.lower()\n",
    "    df = df.str.replace('á', 'a')\n",
    "    df = df.str.replace('é', 'e')\n",
    "    df = df.str.replace('í', 'i')\n",
    "    df = df.str.replace('ó', 'o')\n",
    "    df = df.str.replace('ú', 'u')        \n",
    "\n",
    "    df['Remuneración Bruta Mensualizada'] = df['Remuneración Bruta Mensualizada'].replace(to_replace = \"\\.+\", value=\"\", regex=True)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def getGovernmentData(output_file, url, browser, numEnt):\n",
    "\n",
    "    gov_data = entity_data = createCustomDataFrame()\n",
    "    browser.get(url)\n",
    "\n",
    "    url_list = []\n",
    "    entities = browser.find_elements_by_class_name(\"primaryCat\")\n",
    "\n",
    "    counter = 0\n",
    "    for e in entities:\n",
    "        entity_url = e.get_attribute(\"href\")\n",
    "        url_list.append(entity_url)\n",
    "\n",
    "#    print('Entities:')\n",
    "#    print(url_list)\n",
    "    for url in tqdm_notebook(url_list):\n",
    "        getEntityData(output_file, url, browser)\n",
    "\n",
    "def getEntityData(output_file, url, browser):\n",
    "    browser.get(url)\n",
    "    entity_data = createCustomDataFrame()\n",
    "    \n",
    "    url_list =[]\n",
    "    departments = browser.find_elements_by_class_name(\"primaryCat\")\n",
    "\n",
    "    for d in departments:\n",
    "        department_url = d.get_attribute(\"href\")\n",
    "        url_list.append(department_url)\n",
    "\n",
    "#    print('Departments:')\n",
    "#    print(url_list)\n",
    "    for url in tqdm_notebook(url_list):\n",
    "        getDepartmentData(output_file, url, browser)\n",
    "\n",
    "def getDepartmentData(output_file, url, browser):\n",
    "    department_data = createCustomDataFrame()\n",
    "    \n",
    "    type_contract = ['per_planta', 'per_contrata']\n",
    "    url_list = []\n",
    "\n",
    "    for t in type_contract:\n",
    "        dept_contract_link = url + \"/\" + t\n",
    "        browser.get(dept_contract_link)\n",
    "#        try:\n",
    "        div_years = browser.find_element_by_class_name(\"linksIntermedios\")\n",
    "        unordered_list = div_years.find_element_by_tag_name(\"ul\")\n",
    "        years_links_list = unordered_list.find_elements_by_tag_name(\"li\")\n",
    "        for l in years_links_list:\n",
    "            link_anchor = l.find_element_by_tag_name(\"a\")\n",
    "            year_url = link_anchor.get_attribute(\"href\")\n",
    "            url_list.append(year_url)\n",
    "\n",
    "#    print('Years:')\n",
    "#    print(url_list)\n",
    "    for url in tqdm_notebook(url_list):\n",
    "        getYearData(output_file, url, browser)\n",
    "\n",
    "        \n",
    "        \n",
    "def getYearData(output_file, url, browser):\n",
    "    \n",
    "    # Check if we still have to dive down into the months\n",
    "    div_months = False\n",
    "    try:\n",
    "        div_months = browser.find_element_by_class_name(\"linksIntermedios\")\n",
    "    except NoSuchElementException:\n",
    "        div_months = False\n",
    "\n",
    "    url_list = []\n",
    "    \n",
    "    year_data = createCustomDataFrame()\n",
    "    \n",
    "    if div_months:\n",
    "\n",
    "        unordered_list = div_months.find_element_by_tag_name('ul')\n",
    "        months_links_list = unordered_list.find_elements_by_tag_name('li')\n",
    "\n",
    "        for m in months_links_list:\n",
    "            month_link = m.find_element_by_tag_name('a')\n",
    "            month_url = month_link.get_attribute('href')\n",
    "            url_list.append(month_url)\n",
    "\n",
    "    else:\n",
    "        url_list.append(url)\n",
    "    \n",
    "    for url in url_list:\n",
    "        print(url)\n",
    "    \n",
    "    for url in tqdm_notebook(url_list):  # debug purposes\n",
    "        getDatainPage(output_file, url, browser)\n",
    "\n",
    "    \n",
    "\n",
    "def getDatainPage(output_file, url, browser):\n",
    "\n",
    "    browser.get(url)\n",
    "\n",
    "    table_links = []\n",
    "    table_links.append(url)\n",
    "\n",
    "    try:\n",
    "        pagination = browser.find_element_by_class_name(\"pagination\")\n",
    "        pages = pagination.find_elements_by_tag_name(\"li\")\n",
    "\n",
    "        for page in pages:\n",
    "            try:\n",
    "                link_element = page.find_element_by_tag_name(\"a\")\n",
    "                link = link_element.get_attribute(\"href\")\n",
    "                table_links.append(link)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "        # Remove the last element, its the back arrow\n",
    "        del table_links[-1]\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    total_tables = len(table_links)\n",
    "\n",
    "    # Loop through all the pages and record data\n",
    "    for count, i in enumerate(table_links):\n",
    "        try:\n",
    "            if count == 0:\n",
    "                getTableData(output_file, i, browser)\n",
    "            else:\n",
    "                getTableData(output_file, i, browser)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def getTableData(output_file, url, browser):\n",
    "    browser.get(url)\n",
    "\n",
    "    #######\n",
    "    ### 1 Get table metadata from the breadcrumb (Year, Department, Kind of contract, ...)\n",
    "    #######\n",
    "\n",
    "    try:\n",
    "        table_location_data = browser.find_element_by_class_name(\"breadcrumb\")\n",
    "        breadcrumb_items = table_location_data.find_elements_by_tag_name(\"li\")\n",
    "        num_breadcrumbs = len(breadcrumb_items)\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print ('could not get breadcrumbs from ' + url)\n",
    "        f = open('./output/log_not_opened.txt', 'a')\n",
    "        f.write(url + +',' + 'Error Reading Page' + \"\\n\");\n",
    "        f.close()\n",
    "\n",
    "    entity = breadcrumb_items[1].text\n",
    "    department = breadcrumb_items[2].text\n",
    "    type_contract = breadcrumb_items[3].text\n",
    "    year = breadcrumb_items[4].text\n",
    "    if num_breadcrumbs == 6:\n",
    "        month = breadcrumb_items[5]\n",
    "    else:\n",
    "        month = 'allyear'\n",
    "\n",
    "        #######\n",
    "        ### 2 Get Data of table\n",
    "        #######\n",
    "\n",
    "    try:\n",
    "        data = browser.find_elements_by_tag_name(\"table\")\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        print ('could not get table from ' + url)\n",
    "        f = open('./output/log_not_opened.txt', 'a')\n",
    "        f.write(url + +',' + 'Error Reading Page' + \"\\n\");\n",
    "        f.close()\n",
    "\n",
    "    for i in data:\n",
    "\n",
    "        # Headers\n",
    "        head = i.find_elements_by_tag_name(\"thead\")\n",
    "        for j in head:\n",
    "            header_row = j.find_elements_by_tag_name(\"th\")\n",
    "\n",
    "            # Get length and list of headers\n",
    "            ncol = len(header_row)\n",
    "\n",
    "            headers = list()\n",
    "            # Add table location variables\n",
    "            headers_add = ['entity', 'department', 'type_contract',\n",
    "                          'year', 'month']\n",
    "\n",
    "            for h in headers_add:\n",
    "                headers.append(h)\n",
    "            # Now add actual data row values\n",
    "            for k in header_row:\n",
    "                headers.append(k.text)\n",
    "\n",
    "            headers.append('url')\n",
    "\n",
    "        # Prepare data frame\n",
    "        df = pd.DataFrame(columns=headers)\n",
    "\n",
    "        # Actual Data\n",
    "        table_data = i.find_elements_by_tag_name(\"tbody\")\n",
    "\n",
    "        for j in table_data:\n",
    "            data_row = j.find_elements_by_tag_name(\"tr\")\n",
    "\n",
    "            # Get length and list of data rows\n",
    "            nrow = len(data_row)      \n",
    "            extracted_rows = 0\n",
    "            master_list = list()\n",
    "            for count, k in enumerate(data_row):\n",
    "#                    t1 = time.time()\n",
    "#                    print('Starting to parse row' + str(count) + ' of ' + str(nrow) + '\\n')\n",
    "\n",
    "                data_element = k.find_elements_by_tag_name(\"td\")\n",
    "\n",
    "                # Process only if there is data in the row\n",
    "                if len(data_element) != 0:\n",
    "                    actual_record = list()\n",
    "\n",
    "                    # Add table location variables\n",
    "                    actual_record.append(entity)\n",
    "                    actual_record.append(department)\n",
    "                    actual_record.append(type_contract)\n",
    "                    actual_record.append(year)\n",
    "                    actual_record.append(month)\n",
    "\n",
    "                    # Populate list with actual record\n",
    "\n",
    "                    for l in data_element:\n",
    "                        actual_record.append(l.text)\n",
    "\n",
    "                    # Add url\n",
    "                    actual_record.append(url)\n",
    "\n",
    "                    master_list.append(actual_record)\n",
    "                    extracted_rows += 1\n",
    "#                        t2 = time.time()\n",
    "#                        print('Finished ' + str(t2 - t1))\n",
    "\n",
    "    df = pd.DataFrame(master_list, columns = headers)\n",
    "\n",
    "\n",
    "    try:\n",
    "        f = open(output_file, 'a')\n",
    "        df.to_csv(f, header=False)    \n",
    "        f.close()\n",
    "        \n",
    "        a = open('./output/log_opened.txt', 'a')\n",
    "        a.write(url + ',' + str( time.time()  ) + \"\\n\");\n",
    "        a.close()\n",
    "\n",
    "    except:\n",
    "        print ('could not get data from ' + url)\n",
    "        g = open('./output/log_error.txt', 'a')\n",
    "        g.write(url + ',' + 'Error writing' + \"\\n\");\n",
    "        g.close()\n",
    "\n",
    "#        return(None)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2016\n",
      "http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2015\n",
      "http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2014\n",
      "http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2013\n",
      "http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2012\n",
      "http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2011\n",
      "http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2010\n",
      "http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2009\n",
      "http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2008\n",
      "http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2007\n",
      "http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = './output/scraped_data_2.csv'\n",
    "\n",
    "url = 'http://www.gobiernotransparentechile.cl/directorio/entidad'\n",
    "browser = webdriver.Firefox()\n",
    "\n",
    "df = getGovernmentData(output, url, browser, 1)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "18b6d1a2145c4e4ea5832a6e174b5ac5": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "207087b125d64dd8b112b15f76f5540e": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "5ba6030f694e43dba5ed6fc89a2046d0": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "5c7306cc6e434988aa074d66696bc923": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "858f64fced01480e8a1ee5231b12296e": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "869229ec27db4e94892da682321eb78f": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "a4f185f9e81a495096fabe8e2b3495a9": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "b61987b9775d45c296592fddc462f418": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "be5b02ff11b846d986ba4e992016030e": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "c2cc8573996e4e2389f1a960d78d91c2": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "c5da7f967f6f45a088cbdefd0ca5cd54": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "d5f6a32b4cda46da8944206c50dbb522": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "db0da9d3b1c841a38091f87aaa819a41": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "f3aea6b0a3d3476a852e48957f16fcce": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
