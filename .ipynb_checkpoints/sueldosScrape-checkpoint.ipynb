{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Web Scraping Gobierno Transparente Chile\n",
    "##### Exploring wage expenses in the goberment. Public information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Beautiful soup did not work. The server time outs when you connect through bsoup.\n",
    "\n",
    "## Trying Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import unicodedata\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import sys\n",
    "sys.path.append('./lib/')\n",
    "#from functions import *\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from unidecode import unidecode\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def createCustomDataFrame():\n",
    "   \n",
    "    columns = ['entity', 'department', 'type_contract', 'year', 'month', 'Estamento', 'Apellido paterno', 'Apellido materno', 'Nombres', 'Grado EUS',\t'Calificación profesional o formación', 'Cargo', 'Región',\t'Asignaciones especiales', 'Unidad monetaria', 'Remuneración Bruta Mensualizada', 'Horas extraordinarias', 'Fecha de inicio', 'Fecha de término', 'Observaciones']\n",
    "    \n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    #df = cleanData(df)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "def cleanData(df):\n",
    "\n",
    "# Another way to do the same\n",
    "#    pd.concat([df[col].astype(str).str.upper() for col in df.columns], axis=1)\n",
    "    df = df.str.lower()\n",
    "    df = df.str.replace('á', 'a')\n",
    "    df = df.str.replace('é', 'e')\n",
    "    df = df.str.replace('í', 'i')\n",
    "    df = df.str.replace('ó', 'o')\n",
    "    df = df.str.replace('ú', 'u')        \n",
    "\n",
    "    df['Remuneración Bruta Mensualizada'] = df['Remuneración Bruta Mensualizada'].replace(to_replace = \"\\.+\", value=\"\", regex=True)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def getGovernmentData(output_file, url, browser, numEnt):\n",
    "\n",
    "    gov_data = entity_data = createCustomDataFrame()\n",
    "    browser.get(url)\n",
    "\n",
    "    url_list = []\n",
    "    entities = browser.find_elements_by_class_name(\"primaryCat\")\n",
    "\n",
    "    counter = 0\n",
    "    for e in entities:\n",
    "        entity_url = e.get_attribute(\"href\")\n",
    "        url_list.append(entity_url)\n",
    "\n",
    "    print('Entities:')\n",
    "    print(url_list)\n",
    "    for url in tqdm_notebook(url_list):\n",
    "        entity_data = getEntityData(output_file, url, browser)\n",
    "        gov_data = pd.concat([gov_data, entity_data])\n",
    "#        counter = counter + 1\n",
    "#        if counter == numEnt:\n",
    "#            break\n",
    "\n",
    "    return(gov_data)\n",
    "\n",
    "def getEntityData(output_file, url, browser):\n",
    "    browser.get(url)\n",
    "    entity_data = createCustomDataFrame()\n",
    "    \n",
    "    url_list =[]\n",
    "    departments = browser.find_elements_by_class_name(\"primaryCat\")\n",
    "\n",
    "    for d in departments:\n",
    "        department_url = d.get_attribute(\"href\")\n",
    "        url_list.append(department_url)\n",
    "\n",
    "    print('Departments:')\n",
    "    print(url_list)\n",
    "    for url in tqdm_notebook(url_list):\n",
    "        department_data = getDepartmentData(output_file, url, browser)\n",
    "        entity_data = pd.concat([entity_data,department_data])\n",
    "\n",
    "    return(entity_data)\n",
    "\n",
    "def getDepartmentData(output_file, url, browser):\n",
    "    department_data = createCustomDataFrame()\n",
    "    \n",
    "    type_contract = ['per_planta', 'per_contrata']\n",
    "    url_list = []\n",
    "\n",
    "    for t in type_contract:\n",
    "        dept_contract_link = url + \"/\" + t\n",
    "        browser.get(dept_contract_link)\n",
    "#        try:\n",
    "        div_years = browser.find_element_by_class_name(\"linksIntermedios\")\n",
    "        unordered_list = div_years.find_element_by_tag_name(\"ul\")\n",
    "        years_links_list = unordered_list.find_elements_by_tag_name(\"li\")\n",
    "        for l in years_links_list:\n",
    "            link_anchor = l.find_element_by_tag_name(\"a\")\n",
    "            year_url = link_anchor.get_attribute(\"href\")\n",
    "            url_list.append(year_url)\n",
    "\n",
    "    print('Years:')\n",
    "    print(url_list)\n",
    "    for url in tqdm_notebook(url_list):\n",
    "        year_data = getYearData(output_file, url, browser)\n",
    "        department_data = pd.concat([department_data,year_data])\n",
    "\n",
    "#        except:\n",
    "#            print('Could not get data from' + dept_contract_link)\n",
    "#            pass\n",
    "\n",
    "    return(department_data)\n",
    "        \n",
    "        \n",
    "        \n",
    "def getYearData(output_file, url, browser):\n",
    "    \n",
    "    # Check if we still have to dive down into the months\n",
    "    div_months = False\n",
    "    try:\n",
    "        div_months = browser.find_element_by_class_name(\"linksIntermedios\")\n",
    "    except NoSuchElementException:\n",
    "        div_months = False\n",
    "\n",
    "    url_list = []\n",
    "    \n",
    "    year_data = createCustomDataFrame()\n",
    "    \n",
    "    if div_months:\n",
    "\n",
    "        unordered_list = div_months.find_element_by_tag_name('ul')\n",
    "        months_links_list = unordered_list.find_elements_by_tag_name('li')\n",
    "\n",
    "        for m in months_links_list:\n",
    "            month_link = m.find_element_by_tag_name('a')\n",
    "            month_url = month_link.get_attribute('href')\n",
    "            url_list.append(month_url)\n",
    "\n",
    "    else:\n",
    "        url_list.append(url)\n",
    "    \n",
    "    print(url_list)\n",
    "    \n",
    "    for url in tqdm_notebook(url_list):  # debug purposes\n",
    "        data = getDatainPage(output_file, url, browser)\n",
    "        year_data = pd.concat([year_data, data])\n",
    "\n",
    "    return(year_data)\n",
    "    \n",
    "\n",
    "def getDatainPage(output_file, url, browser):\n",
    "\n",
    "    browser.get(url)\n",
    "\n",
    "    table_links = []\n",
    "    table_links.append(url)\n",
    "\n",
    "    try:\n",
    "        pagination = browser.find_element_by_class_name(\"pagination\")\n",
    "        pages = pagination.find_elements_by_tag_name(\"li\")\n",
    "\n",
    "        for page in pages:\n",
    "            try:\n",
    "                link_element = page.find_element_by_tag_name(\"a\")\n",
    "                link = link_element.get_attribute(\"href\")\n",
    "                table_links.append(link)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "        # Remove the last element, its the back arrow\n",
    "        del table_links[-1]\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    total_tables = len(table_links)\n",
    "\n",
    "    # Loop through all the pages and record data\n",
    "    for count, i in enumerate(table_links):\n",
    "\n",
    "        try:\n",
    "            if count == 0:\n",
    "                data = getTableData(output_file, i, browser)\n",
    "            else:\n",
    "                data1 = getTableData(output_file, i, browser)\n",
    "                data = pd.concat([data, data1])\n",
    "            \n",
    "            f = open('./output/log_opened.txt', 'a')\n",
    "            f.write(i + \"\\n\");\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print ('could not get data from ' + i)\n",
    "            f = open('./output/log_not_opened.txt', 'a')\n",
    "            f.write(i + \"\\n\");\n",
    "\n",
    "    \n",
    "    return(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getTableData(output_file, url, browser):\n",
    "\n",
    "    \n",
    "    browser.get(url)\n",
    "\n",
    "    #######\n",
    "    ### 1 Get table metadata from the breadcrumb (Year, Department, Kind of contract, ...)\n",
    "    #######\n",
    "\n",
    "    try:\n",
    "        table_location_data = browser.find_element_by_class_name(\"breadcrumb\")\n",
    "        breadcrumb_items = table_location_data.find_elements_by_tag_name(\"li\")\n",
    "        num_breadcrumbs = len(breadcrumb_items)\n",
    "\n",
    "        entity = breadcrumb_items[1].text\n",
    "        department = breadcrumb_items[2].text\n",
    "        type_contract = breadcrumb_items[3].text\n",
    "        year = breadcrumb_items[4].text\n",
    "        if num_breadcrumbs == 6:\n",
    "            month = breadcrumb_items[5]\n",
    "        else:\n",
    "            month = 'allyear'\n",
    "\n",
    "        #######\n",
    "        ### 2 Get Data of table\n",
    "        #######\n",
    "\n",
    "        data = browser.find_elements_by_tag_name(\"table\")\n",
    "\n",
    "        for i in data:\n",
    "\n",
    "            # Headers\n",
    "            head = i.find_elements_by_tag_name(\"thead\")\n",
    "            for j in head:\n",
    "                header_row = j.find_elements_by_tag_name(\"th\")\n",
    "\n",
    "                # Get length and list of headers\n",
    "                ncol = len(header_row)\n",
    "\n",
    "                headers = list()\n",
    "                # Add table location variables\n",
    "                headers_add = ['entity', 'department', 'type_contract',\n",
    "                              'year', 'month']\n",
    "\n",
    "                for h in headers_add:\n",
    "                    headers.append(h)\n",
    "                # Now add actual data row values\n",
    "                for k in header_row:\n",
    "                    headers.append(k.text)\n",
    "\n",
    "                headers.append('url')\n",
    "\n",
    "            # Prepare data frame\n",
    "            df = pd.DataFrame(columns=headers)\n",
    "\n",
    "            # Actual Data\n",
    "            table_data = i.find_elements_by_tag_name(\"tbody\")\n",
    "\n",
    "            for j in table_data:\n",
    "                data_row = j.find_elements_by_tag_name(\"tr\")\n",
    "\n",
    "                # Get length and list of data rows\n",
    "                nrow = len(data_row)      \n",
    "                extracted_rows = 0\n",
    "                master_list = list()\n",
    "                for count, k in enumerate(data_row):\n",
    "#                    t1 = time.time()\n",
    "#                    print('Starting to parse row' + str(count) + ' of ' + str(nrow) + '\\n')\n",
    "\n",
    "                    data_element = k.find_elements_by_tag_name(\"td\")\n",
    "\n",
    "                    # Process only if there is data in the row\n",
    "                    if len(data_element) != 0:\n",
    "                        actual_record = list()\n",
    "\n",
    "                        # Add table location variables\n",
    "                        actual_record.append(entity)\n",
    "                        actual_record.append(department)\n",
    "                        actual_record.append(type_contract)\n",
    "                        actual_record.append(year)\n",
    "                        actual_record.append(month)\n",
    "\n",
    "                        # Populate list with actual record\n",
    "                        \n",
    "                        for l in data_element:\n",
    "                            actual_record.append(l.text)\n",
    "\n",
    "                        # Add url\n",
    "                        actual_record.append(url)\n",
    "\n",
    "                        master_list.append(actual_record)\n",
    "                        extracted_rows += 1\n",
    "#                        t2 = time.time()\n",
    "#                        print('Finished ' + str(t2 - t1))\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(master_list, columns = headers)\n",
    "#        df = cleanData(df)\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print ('could not get data from ' + url)\n",
    "        f = open('./output/log_not_opened.txt', 'a')\n",
    "        f.write(url + +',' + 'Error Reading Page' + \"\\n\");\n",
    "        f.close()\n",
    "        return(None)\n",
    "\n",
    "    try:\n",
    "        f = open(output_file, 'a')\n",
    "        df.to_csv(f, header=False)    \n",
    "        f.close()\n",
    "        return(df)\n",
    "\n",
    "    except:\n",
    "        print ('could not get data from ' + url)\n",
    "        f = open('./output/log_not_opened.txt', 'a')\n",
    "        f.write(url + ',' + 'Error writing' + \"\\n\");\n",
    "\n",
    "        return(None)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = './output/scraped_data_2.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities:\n",
      "['http://www.gobiernotransparentechile.cl/directorio/entidad/1', 'http://www.gobiernotransparentechile.cl/directorio/entidad/2', 'http://www.gobiernotransparentechile.cl/directorio/entidad/3', 'http://www.gobiernotransparentechile.cl/directorio/entidad/4', 'http://www.gobiernotransparentechile.cl/directorio/entidad/5', 'http://www.gobiernotransparentechile.cl/directorio/entidad/6', 'http://www.gobiernotransparentechile.cl/directorio/entidad/7', 'http://www.gobiernotransparentechile.cl/directorio/entidad/8', 'http://www.gobiernotransparentechile.cl/directorio/entidad/9', 'http://www.gobiernotransparentechile.cl/directorio/entidad/10', 'http://www.gobiernotransparentechile.cl/directorio/entidad/11', 'http://www.gobiernotransparentechile.cl/directorio/entidad/12', 'http://www.gobiernotransparentechile.cl/directorio/entidad/13', 'http://www.gobiernotransparentechile.cl/directorio/entidad/14', 'http://www.gobiernotransparentechile.cl/directorio/entidad/15', 'http://www.gobiernotransparentechile.cl/directorio/entidad/16', 'http://www.gobiernotransparentechile.cl/directorio/entidad/17', 'http://www.gobiernotransparentechile.cl/directorio/entidad/18', 'http://www.gobiernotransparentechile.cl/directorio/entidad/19', 'http://www.gobiernotransparentechile.cl/directorio/entidad/20', 'http://www.gobiernotransparentechile.cl/directorio/entidad/21', 'http://www.gobiernotransparentechile.cl/directorio/entidad/22', 'http://www.gobiernotransparentechile.cl/directorio/entidad/23', 'http://www.gobiernotransparentechile.cl/directorio/entidad/24', 'http://www.gobiernotransparentechile.cl/directorio/entidad/25', 'http://www.gobiernotransparentechile.cl/directorio/entidad/26']\n",
      "Departments:\n",
      "['http://www.gobiernotransparentechile.cl/directorio/entidad/1/1']\n",
      "Years:\n",
      "['http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2016', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2015', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2014', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2013', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2012', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2011', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2010', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2009', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2008', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2007', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2006', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2016', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2015', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2014', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2013', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2012', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2011', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2010', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2009', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2008', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2007', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2006']\n",
      "['http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2016', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2015', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2014', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2013', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2012', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2011', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2010', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2009', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2008', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2007', 'http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_contrata/Ao-2006']\n",
      "['http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2015']\n",
      "could not get data from http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2015\n",
      "could not get data from http://www.gobiernotransparentechile.cl/directorio/entidad/1/1/per_planta/Ao-2015?x=0&y=0&page_number=2&sort=id&direction=asc\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All objects passed were None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5e37c65b3a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFirefox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetGovernmentData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-126c1316fb1a>\u001b[0m in \u001b[0;36mgetGovernmentData\u001b[0;34m(output_file, url, browser, numEnt)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mentity_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetEntityData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mgov_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgov_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[1;31m#        counter = counter + 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-126c1316fb1a>\u001b[0m in \u001b[0;36mgetEntityData\u001b[0;34m(output_file, url, browser)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mdepartment_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDepartmentData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mentity_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mentity_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepartment_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-126c1316fb1a>\u001b[0m in \u001b[0;36mgetDepartmentData\u001b[0;34m(output_file, url, browser)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0myear_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetYearData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mdepartment_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdepartment_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myear_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-126c1316fb1a>\u001b[0m in \u001b[0;36mgetYearData\u001b[0;34m(output_file, url, browser)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# debug purposes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDatainPage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0myear_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0myear_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-126c1316fb1a>\u001b[0m in \u001b[0;36mgetDatainPage\u001b[0;34m(output_file, url, browser)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mdata1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetTableData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./output/log_opened.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jgaci\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\tools\\merge.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    843\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m    846\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jgaci\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\tools\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'All objects passed were None'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[1;31m# consolidate data & figure out what our result ndim is going to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All objects passed were None"
     ]
    }
   ],
   "source": [
    "url = 'http://www.gobiernotransparentechile.cl/directorio/entidad'\n",
    "browser = webdriver.Firefox()\n",
    "\n",
    "df = getGovernmentData(output, url, browser, 1)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "5234cfaba7c845f3bce6726067601754": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "5eaca9f8de354f7cb3c5e3b014a5e43b": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "8ffbc28fef3d4e4c9ef94332e84b8758": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "c98727b001fa4d2a90ecfbe9e770da23": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "d88138967844400eb4338488f11c8adf": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
